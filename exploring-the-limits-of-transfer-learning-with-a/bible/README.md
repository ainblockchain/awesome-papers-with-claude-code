# Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer Learning Path

A Claude Code-powered interactive learning path based on
"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer" by Raffel et al., 2019.

## Getting Started

1. Open Claude Code in this directory:
   cd exploring-the-limits-of-transfer-learning-with-a/bible/
   claude
2. Start learning â€” just chat naturally:
   explore              # see the knowledge graph
   teach me <concept>   # start a lesson
   give me a challenge  # get a quiz
   done                 # mark complete, move on

## Sharing Progress with Friends

1. Create your learner branch:
   git checkout -b learner/your-name
2. Commit progress as you learn:
   git add .learner/
   git commit -m "Progress update"
   git push origin learner/your-name
3. Fetch friends' branches:
   git fetch --all
   friends

## Course Structure

- **Foundations: Transformers and Transfer Learning** (8 concepts): Core concepts underlying T5: attention mechanisms, Transformer architecture, and the transfer learning paradigm
- **T5 Architecture and Design** (3 concepts): The specific architectural choices in T5: encoder-decoder structure, relative positions, and the text-to-text paradigm
- **Pre-training: Data and Objectives** (4 concepts): How T5 learns from unlabeled text: the C4 dataset, span corruption objective, and training configuration
- **Fine-Tuning and Evaluation** (8 concepts): Adapting T5 to downstream tasks and measuring performance across benchmarks
- **Systematic Studies and Findings** (4 concepts): T5's methodical experiments comparing architectures, objectives, and scaling
- **Legacy and Future Directions** (2 concepts): T5's impact on the field and the research directions it opened

## Stats

- 29 concepts across 6 courses
- 8 foundational, 12 intermediate, 7 advanced, 2 frontier concepts
