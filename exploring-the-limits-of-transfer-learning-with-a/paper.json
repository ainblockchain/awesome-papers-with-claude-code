{
  "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
  "description": "T5 frames every NLP task as text-to-text, systematically exploring transfer learning limits and achieving state-of-the-art results across diverse benchmarks.",
  "arxivId": "1910.10683",
  "githubUrl": "https://github.com/google-research/text-to-text-transfer-transformer",
  "authors": [
    { "name": "Colin Raffel" },
    { "name": "Noam Shazeer" },
    { "name": "Adam Roberts" },
    { "name": "Katherine Lee" },
    { "name": "Sharan Narang" },
    { "name": "Michael Matena" },
    { "name": "Yanqi Zhou" },
    { "name": "Wei Li" },
    { "name": "Peter J. Liu" }
  ],
  "publishedAt": "2019-10-23",
  "organization": { "name": "Google" },
  "submittedBy": "community"
}
