{
  "nodes": [
    {
      "id": "transformer_architecture",
      "name": "Transformer Architecture",
      "type": "architecture",
      "level": "foundational",
      "description": "The foundational neural network architecture introduced in 'Attention Is All You Need' that uses self-attention mechanisms instead of recurrence. GPT-OSS models build upon the autoregressive transformer design from GPT-2 and GPT-3.",
      "key_ideas": [
        "Self-attention allows modeling long-range dependencies",
        "Encoder-decoder or decoder-only variants exist",
        "Autoregressive models predict the next token given previous tokens"
      ],
      "code_refs": [],
      "paper_ref": "Vaswani et al., 2017 — Attention Is All You Need",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "mixture_of_experts",
      "name": "Mixture of Experts (MoE)",
      "type": "architecture",
      "level": "foundational",
      "description": "An architecture that uses multiple specialized sub-networks (experts) with a routing mechanism to select which experts process each input. This enables scaling model parameters while keeping computation sparse.",
      "key_ideas": [
        "Only a subset of parameters are active per input",
        "Router network decides which experts to activate",
        "Enables larger models with fixed compute budget"
      ],
      "code_refs": [],
      "paper_ref": "Shazeer et al., 2017 — Outrageously Large Neural Networks",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "moe_transformer_gpt_oss",
      "name": "MoE Transformer in GPT-OSS",
      "type": "architecture",
      "level": "intermediate",
      "description": "GPT-OSS uses an autoregressive MoE transformer with 128 experts (120b) or 32 experts (20b), selecting top-4 experts per token via linear router projection. This gives 116.8B total params with only 5.1B active per token.",
      "key_ideas": [
        "Top-4 expert selection per token",
        "Linear router projection for expert selection",
        "120b: 116.8B total, 5.1B active; 20b: 20.9B total, 3.6B active"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "grouped_query_attention",
      "name": "Grouped Query Attention (GQA)",
      "type": "technique",
      "level": "intermediate",
      "description": "An attention variant that groups query heads to share key-value heads, reducing memory bandwidth during inference. GPT-OSS uses 64 query heads with 8 key-value heads.",
      "key_ideas": [
        "Multiple query heads share the same key-value heads",
        "Reduces KV cache memory requirements",
        "Maintains quality while improving efficiency"
      ],
      "code_refs": [],
      "paper_ref": "Ainslie et al., 2023 — GQA: Training Generalized Multi-Query Transformer Models",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "yarn_context_extension",
      "name": "YaRN Context Extension",
      "type": "technique",
      "level": "intermediate",
      "description": "Yet another RoPE Naturally - a technique to extend transformer context length by modifying rotary position embeddings. GPT-OSS uses YaRN to enable 131,072 token context windows for dense attention layers.",
      "key_ideas": [
        "Extends RoPE to longer sequences without retraining",
        "Enables 128k context length",
        "Applied to dense attention layers in GPT-OSS"
      ],
      "code_refs": [],
      "paper_ref": "Peng et al., 2023 — YaRN: Efficient Context Window Extension of LLMs",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "banded_window_attention",
      "name": "Banded Window Attention",
      "type": "technique",
      "level": "intermediate",
      "description": "GPT-OSS alternates between banded window attention (128-token bandwidth) and dense attention patterns. This reduces computation for long sequences while maintaining global context through interleaved dense layers.",
      "key_ideas": [
        "Local attention within fixed windows",
        "Alternates with dense global attention",
        "128-token bandwidth in GPT-OSS"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "swiglu_activation",
      "name": "SwiGLU Activation",
      "type": "component",
      "level": "foundational",
      "description": "A gated activation function combining Swish and GLU (Gated Linear Unit). GPT-OSS uses Gated SwiGLU with unconventional clamping and residual connections.",
      "key_ideas": [
        "Combines Swish activation with gating mechanism",
        "Outperforms ReLU and GELU in transformers",
        "GPT-OSS adds clamping for stability"
      ],
      "code_refs": [],
      "paper_ref": "Shazeer, 2020 — GLU Variants Improve Transformer",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "mxfp4_quantization",
      "name": "MXFP4 Quantization",
      "type": "optimization",
      "level": "advanced",
      "description": "Microscaling FP4 quantization reduces MoE weights to 4.25 bits per parameter. This enables 120b model on single 80GB GPU and 20b on 16GB systems. Checkpoint sizes are 60.8GiB and 12.8GiB.",
      "key_ideas": [
        "4.25 bits per parameter for MoE weights",
        "Enables consumer hardware deployment",
        "All evaluations performed with quantized weights"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "flash_attention",
      "name": "Flash Attention",
      "type": "optimization",
      "level": "intermediate",
      "description": "An IO-aware attention algorithm that reduces memory access by fusing operations and using tiling. GPT-OSS training used Flash Attention on NVIDIA H100 GPUs.",
      "key_ideas": [
        "Reduces memory IO bottleneck",
        "Fuses softmax and attention computation",
        "Enables longer sequences in fixed memory"
      ],
      "code_refs": [],
      "paper_ref": "Dao et al., 2022 — FlashAttention: Fast and Memory-Efficient Exact Attention",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "chain_of_thought",
      "name": "Chain-of-Thought (CoT) Reasoning",
      "type": "technique",
      "level": "foundational",
      "description": "A prompting technique where models generate intermediate reasoning steps before final answers. GPT-OSS is trained with CoT reinforcement learning similar to OpenAI's o-series models.",
      "key_ideas": [
        "Explicit reasoning improves complex problem solving",
        "Enables 'thinking' before answering",
        "GPT-OSS provides full CoT access for transparency"
      ],
      "code_refs": [],
      "paper_ref": "Wei et al., 2022 — Chain-of-Thought Prompting Elicits Reasoning in LLMs",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "variable_effort_reasoning",
      "name": "Variable Effort Reasoning",
      "type": "technique",
      "level": "advanced",
      "description": "GPT-OSS supports three reasoning levels (low, medium, high) configurable via system prompts. Higher effort produces longer chain-of-thought outputs with improved accuracy - a form of test-time compute scaling.",
      "key_ideas": [
        "Low/medium/high reasoning effort levels",
        "Higher effort = longer CoT = better accuracy",
        "Test-time compute scaling"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "knowledge_distillation",
      "name": "Knowledge Distillation",
      "type": "training",
      "level": "foundational",
      "description": "Training a smaller student model to mimic a larger teacher model's outputs. GPT-OSS uses large-scale distillation as part of its training methodology.",
      "key_ideas": [
        "Student learns from teacher's soft labels",
        "Compresses knowledge into smaller models",
        "Part of GPT-OSS training pipeline"
      ],
      "code_refs": [],
      "paper_ref": "Hinton et al., 2015 — Distilling the Knowledge in a Neural Network",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "reinforcement_learning_from_human_feedback",
      "name": "RLHF (Reinforcement Learning from Human Feedback)",
      "type": "training",
      "level": "foundational",
      "description": "A training paradigm that uses human preferences to train a reward model, then optimizes the language model via reinforcement learning. GPT-OSS uses RL extensively for reasoning and tool use capabilities.",
      "key_ideas": [
        "Human preferences guide model behavior",
        "Reward model provides training signal",
        "PPO or similar algorithms optimize policy"
      ],
      "code_refs": [],
      "paper_ref": "Ouyang et al., 2022 — Training language models to follow instructions with human feedback",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "harmony_chat_format",
      "name": "Harmony Chat Format",
      "type": "technique",
      "level": "intermediate",
      "description": "OpenAI's custom chat format for GPT-OSS featuring special tokens, role-based instruction hierarchy (System > Developer > User > Assistant > Tool), and message channels for different visibility contexts.",
      "key_ideas": [
        "Strict role hierarchy for instruction handling",
        "Special tokens for structured communication",
        "Prevents user override of system guardrails"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "instruction_hierarchy",
      "name": "Instruction Hierarchy",
      "type": "technique",
      "level": "advanced",
      "description": "Post-training enforces privilege-based instruction handling where System > Developer > User > Assistant > Tool. This prevents users from overriding developer or system-level guardrails through prompt injection.",
      "key_ideas": [
        "Hierarchical trust levels for different message sources",
        "Defends against prompt injection attacks",
        "Users cannot override system/developer instructions"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "agentic_tool_use",
      "name": "Agentic Tool Use",
      "type": "application",
      "level": "intermediate",
      "description": "GPT-OSS is trained for native agentic capabilities including web browsing, Python code execution in stateful Jupyter notebooks, and arbitrary developer-defined functions with interleaved CoT.",
      "key_ideas": [
        "Web browsing capability",
        "Stateful Python/Jupyter execution",
        "Function calling with structured outputs"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "function_calling",
      "name": "Function Calling",
      "type": "application",
      "level": "intermediate",
      "description": "The model can invoke external functions defined by developers, receiving structured JSON outputs. This enables integration with external APIs, databases, and tools.",
      "key_ideas": [
        "Structured function invocation",
        "JSON-based arguments and returns",
        "Enables external system integration"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "o200k_harmony_tokenizer",
      "name": "O200K Harmony Tokenizer",
      "type": "tokenization",
      "level": "intermediate",
      "description": "A 201,088-token vocabulary extending OpenAI's o200k tokenizer with specialized tokens for the harmony chat format. Released via the open-source TikToken library.",
      "key_ideas": [
        "Extended vocabulary for chat format",
        "Special tokens for roles and channels",
        "Compatible with TikToken library"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "deliberative_alignment",
      "name": "Deliberative Alignment",
      "type": "training",
      "level": "advanced",
      "description": "A safety training approach where models are trained to refuse disallowed content and resist jailbreaks through explicit deliberation in their chain-of-thought reasoning.",
      "key_ideas": [
        "Models reason about safety in CoT",
        "Trains refusal behavior for harmful requests",
        "Improves jailbreak resistance"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "preparedness_framework",
      "name": "Preparedness Framework",
      "type": "theory",
      "level": "advanced",
      "description": "OpenAI's internal framework for evaluating catastrophic risks in AI models across domains like biosecurity, cybersecurity, and AI self-improvement. GPT-OSS was evaluated against these thresholds.",
      "key_ideas": [
        "Categorizes risk levels for different capability domains",
        "Evaluates bio/chem, cyber, and autonomy risks",
        "GPT-OSS deemed below 'High capability' thresholds"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "adversarial_finetuning",
      "name": "Adversarial Fine-Tuning",
      "type": "training",
      "level": "advanced",
      "description": "OpenAI created adversarially fine-tuned versions of GPT-OSS using helpful-only training and domain-specific data to stress-test safety. These showed the open models don't exceed safety thresholds even when optimized for harm.",
      "key_ideas": [
        "Stress-tests model safety limits",
        "Uses RL with helpful-only objective",
        "Domain-specific dangerous capability training"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "jailbreak_resistance",
      "name": "Jailbreak Resistance",
      "type": "application",
      "level": "advanced",
      "description": "Evaluation of model robustness against adversarial prompts designed to bypass safety measures. GPT-OSS shows comparable performance to o4-mini on StrongReject benchmark.",
      "key_ideas": [
        "Tested against StrongReject benchmark",
        "Instruction hierarchy helps prevent bypasses",
        "Some vulnerability to system prompt extraction"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "benchmark_performance",
      "name": "Benchmark Performance",
      "type": "application",
      "level": "intermediate",
      "description": "GPT-OSS-120b achieves 95.8% on AIME 2024, 80.1% on GPQA Diamond, 90.0% on MMLU, and 62.4% on SWE-Bench. It surpasses o3-mini and approaches o4-mini accuracy.",
      "key_ideas": [
        "Near state-of-the-art on math/reasoning benchmarks",
        "Strong coding performance on SWE-Bench",
        "20b competitive despite being 6x smaller"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "open_weights_release",
      "name": "Open Weights Release",
      "type": "application",
      "level": "frontier",
      "description": "GPT-OSS releases all components under Apache 2.0 license: model weights, inference implementations, tool environments, and tokenizers. This enables community fine-tuning on consumer hardware.",
      "key_ideas": [
        "Apache 2.0 permissive license",
        "Full weights and inference code released",
        "Fine-tunable on consumer GPUs"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    },
    {
      "id": "cot_safety_considerations",
      "name": "Chain-of-Thought Safety Considerations",
      "type": "theory",
      "level": "frontier",
      "description": "OpenAI warns that raw CoT outputs contain unrestricted hallucinated content not aligned with safety policies. Developers should filter CoT before showing to users.",
      "key_ideas": [
        "CoT may contain unsafe content",
        "Requires filtering before user display",
        "Transparency vs safety tradeoff"
      ],
      "code_refs": [],
      "paper_ref": "OpenAI, 2025 — gpt-oss-120b & gpt-oss-20b Model Card",
      "first_appeared": null,
      "confidence": 1.0
    }
  ],
  "edges": [
    {
      "source": "transformer_architecture",
      "target": "moe_transformer_gpt_oss",
      "relationship": "builds_on",
      "weight": 1.0,
      "description": "GPT-OSS MoE transformer builds on the foundational autoregressive transformer architecture"
    },
    {
      "source": "mixture_of_experts",
      "target": "moe_transformer_gpt_oss",
      "relationship": "builds_on",
      "weight": 1.0,
      "description": "GPT-OSS implements MoE with 128/32 experts and top-4 routing"
    },
    {
      "source": "grouped_query_attention",
      "target": "moe_transformer_gpt_oss",
      "relationship": "component_of",
      "weight": 0.9,
      "description": "GQA is used in GPT-OSS attention layers with 64 query and 8 KV heads"
    },
    {
      "source": "yarn_context_extension",
      "target": "moe_transformer_gpt_oss",
      "relationship": "enables",
      "weight": 0.9,
      "description": "YaRN enables 131K context length in GPT-OSS dense attention layers"
    },
    {
      "source": "banded_window_attention",
      "target": "moe_transformer_gpt_oss",
      "relationship": "component_of",
      "weight": 0.8,
      "description": "Alternating banded/dense attention pattern used in GPT-OSS"
    },
    {
      "source": "swiglu_activation",
      "target": "moe_transformer_gpt_oss",
      "relationship": "component_of",
      "weight": 0.8,
      "description": "Gated SwiGLU activation used in GPT-OSS MLP layers"
    },
    {
      "source": "moe_transformer_gpt_oss",
      "target": "mxfp4_quantization",
      "relationship": "optimizes",
      "weight": 1.0,
      "description": "MXFP4 quantization compresses GPT-OSS MoE weights to 4.25 bits"
    },
    {
      "source": "flash_attention",
      "target": "moe_transformer_gpt_oss",
      "relationship": "optimizes",
      "weight": 0.8,
      "description": "Flash Attention accelerated GPT-OSS training on H100 GPUs"
    },
    {
      "source": "chain_of_thought",
      "target": "variable_effort_reasoning",
      "relationship": "builds_on",
      "weight": 1.0,
      "description": "Variable effort reasoning extends CoT with configurable reasoning depth"
    },
    {
      "source": "reinforcement_learning_from_human_feedback",
      "target": "variable_effort_reasoning",
      "relationship": "enables",
      "weight": 0.9,
      "description": "RL training enables GPT-OSS reasoning capabilities"
    },
    {
      "source": "knowledge_distillation",
      "target": "moe_transformer_gpt_oss",
      "relationship": "enables",
      "weight": 0.8,
      "description": "Large-scale distillation part of GPT-OSS training"
    },
    {
      "source": "reinforcement_learning_from_human_feedback",
      "target": "harmony_chat_format",
      "relationship": "enables",
      "weight": 0.9,
      "description": "RL post-training teaches GPT-OSS the harmony format"
    },
    {
      "source": "harmony_chat_format",
      "target": "instruction_hierarchy",
      "relationship": "enables",
      "weight": 1.0,
      "description": "Harmony format implements the instruction hierarchy system"
    },
    {
      "source": "instruction_hierarchy",
      "target": "jailbreak_resistance",
      "relationship": "enables",
      "weight": 0.9,
      "description": "Hierarchical instruction handling improves jailbreak resistance"
    },
    {
      "source": "chain_of_thought",
      "target": "agentic_tool_use",
      "relationship": "enables",
      "weight": 0.9,
      "description": "CoT reasoning enables interleaved tool calls"
    },
    {
      "source": "agentic_tool_use",
      "target": "function_calling",
      "relationship": "component_of",
      "weight": 0.9,
      "description": "Function calling is a key agentic capability"
    },
    {
      "source": "o200k_harmony_tokenizer",
      "target": "harmony_chat_format",
      "relationship": "enables",
      "weight": 0.9,
      "description": "Harmony tokenizer provides special tokens for chat format"
    },
    {
      "source": "reinforcement_learning_from_human_feedback",
      "target": "deliberative_alignment",
      "relationship": "enables",
      "weight": 0.9,
      "description": "RL training implements deliberative alignment for safety"
    },
    {
      "source": "deliberative_alignment",
      "target": "jailbreak_resistance",
      "relationship": "enables",
      "weight": 0.9,
      "description": "Deliberative alignment improves jailbreak resistance"
    },
    {
      "source": "preparedness_framework",
      "target": "adversarial_finetuning",
      "relationship": "requires",
      "weight": 0.8,
      "description": "Preparedness evaluation uses adversarial fine-tuning"
    },
    {
      "source": "adversarial_finetuning",
      "target": "open_weights_release",
      "relationship": "enables",
      "weight": 0.8,
      "description": "Adversarial testing validated safety for open release"
    },
    {
      "source": "variable_effort_reasoning",
      "target": "benchmark_performance",
      "relationship": "enables",
      "weight": 0.9,
      "description": "Variable reasoning effort drives benchmark scores"
    },
    {
      "source": "agentic_tool_use",
      "target": "benchmark_performance",
      "relationship": "enables",
      "weight": 0.8,
      "description": "Tool use contributes to benchmark performance"
    },
    {
      "source": "mxfp4_quantization",
      "target": "open_weights_release",
      "relationship": "enables",
      "weight": 0.9,
      "description": "Quantization enables deployment on consumer hardware"
    },
    {
      "source": "chain_of_thought",
      "target": "cot_safety_considerations",
      "relationship": "requires",
      "weight": 0.9,
      "description": "CoT transparency raises safety filtering requirements"
    },
    {
      "source": "open_weights_release",
      "target": "cot_safety_considerations",
      "relationship": "requires",
      "weight": 0.8,
      "description": "Open release requires developers handle CoT safety"
    }
  ]
}
